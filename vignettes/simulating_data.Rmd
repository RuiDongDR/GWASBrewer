---
title: "Simulating Data"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Simulating Data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(simGWAS)
library(DiagrammeR)
library(dplyr)
library(reshape2)
library(ggplot2)
set.seed(1)
```

## Introduction

This vignette demonstrates how to use the `sim_mv` function to simulate data a few different types of GWAS data.

## Introduction to `sim_mv`

The `sim_mv` function generates GWAS summary statistics for multiple continuous traits from a linear structural 
equation model encoded as a matrix of direct effects. Variants can be generated with or without LD.
There are also some helper functions for LD-pruning and generating special kinds of direct effect matrices. 

The `sim_mv` function is a wrapper to a more general function `sim_lf` which generates summary statistics given 
a latent factor structure for a set of traits. 


## Basic Usage

### Input 

The `sim_mv` function has five required arguments:

+ `N`: The GWAS sample size for each trait. This can be a scalar, vector or matrix. If a vector, `N` should have length equal to the number of traits. If there are overlapping samples between GWAS, `N` should be a matrix (see "Sample Overlap" below). 
+ `J`: The number of SNPs to simulate (scalar).
+ `h2`: The hertiability of each trait. This can be a scalar or a vector with length equal to the number of traits generated.
+ `pi`: The proportion of all SNPs that have a direct effect on each trait. This can be a scalar or a vector with length equal to the number of traits generated.
+ `G`: A matrix specifying direct effects in the linear structural equation model. For `M` traits with no causal relationships, use `G = matrix(0, nrow = M, ncol = M )` or the shorthand `G = M`. 

There are additional optional arguments:

+ `R_E` and `R_obs`: Alternative ways to specify the correlation of environmental traut components of each trait (see "Sample Overlap" section below for more details).
+ `R_LD`: A list of LD blocks (See "Simulating Data with LD"). 
+ `af`: Optional vector of allele frequencies (required if `R_LD` is specified). 
+ `sporadic_pleiotropy`: Allow a single variant to have direct effects on multiple traits at random. Defaults to TRUE.
+ `pi_exact`: If TRUE, the number of direct effect SNPs for each trait will be exactly equal to `round(pi*J)`. Defaults to FALSE.
+ `h2_exact`: If TRUE, the heritability of each trait will be exactly `h2`. Defaults to FALSE.
+ `est_s`: If TRUE, return estimates of se(beta_hat). Currently defaults to FALSE but this is probably generally a good option to use.
+ `return_dat`: A developer option, return some extra data that is useful for debugging and testing. 


### Output

The `sim_mv` function returns a list with the following elements

GWAS summary statistics are contained in two or three matrices:

+ `beta_hat`: Simulated GWAS effect estimates and standard errors.
+ `se_beta_hat`: True standard errors of `beta_hat`.
+ `s_estimate`: If `est_s= TRUE` then a simulated estimate of `se_beta_hat`.

True marginal and joint, total and direct effects are contained in four matrices:

+ `beta_joint`: Total causal effects of SNPs on traits. 
+ `beta_marg`: Expected marginal association of SNPs on traits. `beta_marg` is the expected value of `beta_hat`. When there is no 
LD, `beta_marg` and `beta_joint` are the same. 
+ `direct_SNP_effects_joint`: Direct causal effects of SNPs on traits. Direct means not mediated by other traits. 
+ `direct_SNP_effects_marg`: Like `beta_marg` but considering only direct rather than total effects. 

The relationship between traits is contained in two matrices:

+ `direct_trait_effects`: Matrix of direct effects between traits
+ `total_trait_effects`: Matrix of total effects between traits

Trait covariance is described by four matrices:

+ `Sigma_G`: Genetic variance-covariance matrix, determined by heritability and `G`.
+ `Sigma_E`: Environmental variance-covariance matrix. This is determined by heritability and `R_E`.
+ `trait_corr`: Population trait correlation, equal to `Sigma_G + Sigma_E`. 
+ `R`: Correlation in sampling error of `beta_hat` across traits, equal to `trait_corr` scaled by a matrix of sample overlap proportions. 

The order of the columns of all results corresponds
to the order of variables in `G`. 

## Specifying the DAG

The matrix `G` specifies a linear structural equation model for a set of traits. 
To generate a set of $M$ traits with no causal relationships, `G` can be set either equal to `M` or to an $M\times M$ matrix of 0's. Otherwise,
`G` must be an $M \times M$ matrix with `G[i,j]` specifying the direct linear effect of trait $i$ on trait $j$. The
diagonal entries of $G$ should be 0 (no self effects). An error will be generated if `G` specifies a graph that contains cycles. All traits are assumed to have variance 
equal to 1, so `G[i,j]^2` is the proportion of trait $j$ variance explained by 
the direct effect of trait $i$. 

For example, the matrix
```{r}
G <- matrix(c(0, sqrt(0.25), 0, sqrt(0.15), 
              0, 0, 0, sqrt(0.1), 
              sqrt(0.2), 0, 0, -sqrt(0.3), 
              0, 0, 0, 0), nrow = 4, byrow = TRUE)
colnames(G) <- row.names(G) <- c("X", "Y", "Z", "W")
G
```

corresponds to the graph

```{r, echo=FALSE, fig.align='center', fig.width = 5}
d <- melt(G) %>%
     filter(value !=0) %>%
     rename(from = Var1, to = Var2)


n <- create_node_df(n = 4, label = c("X", "Y", "Z", "W"), 
                    fontname = "Helvetica", 
                    fontsize = 10, 
                    width = 0.3, 
                    fillcolor = "white", 
                    fontcolor = "black",
                    color = "black", 
                    x = c(0, 1, 1, 2), 
                    y = c(0, -0.5, 1, 0))
e <- create_edge_df(from = d$from, to = d$to, minlen = 1,  color = "black", 
                    label = round(d$value, digits = 3))
g <- create_graph(nodes_df = n, edges_df = e)

render_graph(g)
```



To simulate data from this graph, we can use

```{r}
sim_dat1 <- sim_mv(G = G,
                   J = 50000,
                  N = 60000,  
                  h2 = c(0.3, 0.3, 0.5, 0.4), 
                  pi = 1000/50000)
```

Using `N = 60000` indicates that all four GWAS have a sample size of 60,000 and that
there is no overlap in samples between GWAS. The `h2` argument provides the heritability
of each trait. The `pi` argument gives the expected proportion of direct effect
variants for each trait. In this case, since `J = 50000` and `pi = 1000/50000`, we expect
each trait to have 1000 direct effect variants. 


Using the default settings, there is some randomness in the number of direct effect
variants and the total heritability. 
We can see the realized values by looking at the `direct_SNP_effects_joint` matrix and `Sigma_G` in the
simulation data object. `Sigma_G` is the realized genetic variance-covariance matrix. The diagonal values are 
the realized heritability of each trait.

```{r}
colSums(sim_dat1$direct_SNP_effects_joint != 0)
sim_dat1$Sigma_G
```

By default, we allow variants to
have direct effects on multiple traits, a phenomenon we refer to as sporadic pleiotropy.
In this case, the majority of variants have direct effects on only one trait but 
`r sum(rowSums(sim_dat1$direct_SNP_effects_joint != 0) > 1)` variants directly affect more than one
trait.
```{r}
A <- data.frame(sim_dat1$direct_SNP_effects_joint != 0) 
names(A) <- paste0("Direct ", c("X", "Y", "Z", "W"), " effect")
group_by_all(A) %>% 
  summarize(n = n()) %>% 
  arrange(-n)
```

These features can be controlled using the `pi_exact`, `h2_exact`, and `sporadic_pleiotropy` options.
Using `pi_exact = TRUE` forces the number of direct effect variants to be exactly equal to `round(pi*J)` (in our case 1000 for each trait).
`h2_exact = TRUE` forces the realized heritability to be
(nearly) exactly equal to the input `h2` and `sporadic_pleiotropy = FALSE` prevents
sporadic pleiotropy. 
If `sporadic_pleiotropy = TRUE` (the default value), `h2_exact` will result in 
trait heritabilities very close, but not exactly equal to `h2`.
Note that some scenarios with either many traits or large values of `pi`
are inconsistent with `sporadic_pleiotropy = FALSE` because 
there are not enough variants to exclude overlap between traits. In these cases
using `sporadic_pleiotropy = FALSE` will result in an error. 

Below, we demonstrate these three options. We can see that the diagonal of `Sigma_G` is now exactly equal to the input heritability, exactly 1000 variants have direct effects on each trait, and there are no variants that directly affect multiple traits.

```{r}
sim_dat2 <- sim_mv(G = G,
                   J = 50000,
                  N = 60000,  
                  h2 = c(0.3, 0.3, 0.5, 0.4), 
                  pi = 1000/50000, 
                  pi_exact = TRUE, 
                  h2_exact = TRUE, 
                  sporadic_pleiotropy = FALSE)

sim_dat2$Sigma_G
A <- data.frame(sim_dat2$direct_SNP_effects_joint != 0) 
names(A) <- paste0("Direct ", c("X", "Y", "Z", "W"), " effect")
group_by_all(A) %>% 
  summarize(n = n()) %>% 
  arrange(-n)
```




### Generating $G$ from "XYZ" mode.

The function `xyz_to_G` will generate a matrix, $G$, corresponding to a specific "XYZ" DAG form. 
In the "XYZ" DAG, 
there is an exposure ($X$), an outcome ($Y$), and $M-2$ other variables, $Z_1, \dots, Z_{M-2}$. 
The XYZ DAG format is an older input format used in early versions of this package. We expect that
most new users will prefer the default  method of 
directly specifying $G$,
but have retained the XYZ format for earlier users and users that find it helpful.

In XYZ format, we specify a (possibly 0) effect of $X$ on $Y$, given by the `gamma` argument. 
Variables $Z_1, \dots, Z_{M-2}$ can have effects either on or from $X$ and on or from $Y$, 
but there are no affects $Z_1, \dots, Z_{M-2}$ on each other. 
Effects between each $Z_m$ and $X$ and $Y$ respectively are given in the `tau_xz` and `tau_yz` arguments. 
The direction of these effects is given in the `dir_xz` and `dir_yz` arguments. All four of
these arguments should have length $M-2$. 

The direction parameters `dir_xz` and `dir_yz` are vectors of 1 or -1 with 1 indicating an effect on $X$ or $Y$ and -1 indicating an effect from $X$ or $Y$. 
Effect size arguments `gamma`, `tau_xz`, and `tau_yz` are given as signed proportion of variance explained. 
So if `gamma = -0.3`, The direct effect of $X$ explains 30\% of the variance of $Y$ and the 
effect of $X$ on $Y$ is negative. 


For example, the code

```{r}
myG <- xyz_to_G(tau_xz = c(0.1, -0.15, 0.2, 0.3), 
                   tau_yz = c(0, 0.2, -0.25, 0.15), 
                   dir_xz = c(1, 1, -1, -1), 
                   dir_yz = c(1, 1, -1, 1),
                   gamma = 0.3)
```

generates the matrix corresponding to the graph below:


```{r, echo=FALSE, fig.align='center', fig.width = 5}

myd <- melt(myG) %>%
     filter(value !=0) %>%
     rename(from = Var1, to = Var2)

n <- create_node_df(n = 6, label = c("Y", "X", "Z1", "Z2", "Z3", "Z4"), 
                    fontname = "Helvetica", 
                    fontsize = 10, 
                    width = 0.3, 
                    fillcolor = "white", 
                    fontcolor = "black",
                    color = "black", 
                    x = c(2, 0, -0.5, 1, 1, 1), 
                    y = c(0, 0, 1, 1, -0.5, -1))
e <- create_edge_df(from = myd$from, to = myd$to, minlen = 1,  color = "black", 
                    label = round(d$value, digits = 3))
g <- create_graph(nodes_df = n, edges_df = e)

render_graph(g)
```


The weights in the graph give the effect size. Note that this is the square root of the value provided in `tau_xz` and `tau_yz` which specifies the percent variance explained. For example, the effect of $Z_1$ on $X$ is  $0.316 = \sqrt{0.1}$ and the effect of $Z_2$ on $X$ is $-0.387 = - \sqrt{0.15}$. The matrix created by `xyz_to_G` can be used in the `G` parameter of `sim_mv`.

## A Closer Look at the Output 

We can now take a look at the output from running `sim_mv`. Summary statistics are contained in the `beta_hat`, `se_beta_hat`, and if `est_s = TRUE` was used, `s_estimate`. These all  have dimension $J\times M$ where $M$ is the number of traits.
```{r}
names(sim_dat1)
dim(sim_dat1$beta_hat)
head(sim_dat1$beta_hat)
head(sim_dat1$se_beta_hat)
```

The `direct_trait_effects` object is a matrix giving the input `G` while `total_trait_effects` gives the total effect of each trait on each other trait. 
```{r}
sim_dat1$direct_trait_effects
sim_dat1$total_trait_effects
```

True variant effects are also stored in the simulation object. The `direct_SNP_effects_joint` and `beta_joint` objects give the direct and total SNP effects. The `_joint` ending indicates that these variables store the expected *joint* association, conditional on all other variants, i.e. the causal effects. GWAS effect estimates measure the marginal association, so we also store the expected direct and total *marginal* associations in 
`direct_SNP_effects_marg` and `beta_marg`. When all variants are independent (no LD),  the expected joint and marginal associations are the same. 

```{r}
all.equal(sim_dat1$beta_joint, sim_dat1$beta_marg)
```

If we had generated data with LD, this would not be the case (see below for more on LD). `beta_marg` is always the expected value of `beta_hat`.

Direct SNP effects are always independent across traits while total SNP effects are the sum of direct effects and indirect effects mediated by other traits. To see the difference, we make some plots.

First we plot direct SNP effects on $Z$ vs direct SNP effects on $W$
```{r}
plot(sim_dat1$direct_SNP_effects_joint[,3], sim_dat1$direct_SNP_effects_joint[,4], 
     xlab = "Direct Z effect", ylab = "Direct W effect")
```

Most variants have direct effects on at most one of $Z$ or $W$ but a small number affect both because `sporadic_pleiotropy = TRUE` by default. 

Next we plot the total SNP effects on $Z$ vs the total SNP effects on $W$. Because $Z$ has a causal effect on $W$, all variants with effects on $Z$ also affect $W$. The line in the plot has slope equal to the total effect of $Z$ on $W$. The majority SNPs that have non-zero effect on $Z$ fall exactly on this line. With `sporadic_pleiotropy= FALSE`, all of the variants with non-zero effect on $Z$ would fall on this line. The variants on the vertical line at 0 are variants with non-zero direct effect on $W$ but no direct effect on $Z$. 

```{r}
plot(sim_dat1$beta_joint[,3], sim_dat1$beta_joint[,4], 
     xlab = "Total Z effect", ylab = "Total W effect")
abline(0, sim_dat1$total_trait_effects[3,4], col = "red", lty = 2, lwd = 2)
```

Finally, we can verify that the observed GWAS effect estimate is a noisy measurement of `beta_marg` (in this case equal to `beta_joint` plotted above).

```{r}
plot(sim_dat1$beta_marg[,3], sim_dat1$beta_hat[,3], 
     xlab = "beta_marg[,3] = E[beta_hat[,3]]", ylab = "beta_hat[,3]")
abline(0, 1, col = "red", lty = 2, lwd = 2)
```

## Standardized vs Non-Standardized Effects

If the `af` argument is omitted, 
`sim_mv` returns standardized effects and standardized effect estimates. 
These are the estimates we would obtain if genotypes were scaled to have population variance 1 rather than being coded as 0, 1, and 2. The relationship between standardized and non-standardized effect estimates is $\hat{\beta}_j^{(non-std)} = \hat{\beta}_j^{(std)}/sd(g_j)$ where $j$ indexes variants, $sd(g_j)$ is the population standard deviation of variant $j$ (i.e. $\sqrt{2 f_j (1-f_j)}$ where $f_j$ is the allele frequency of variant $j$). Similarly the relationship between the standard error of standardized and non-standardized effect estimates is $se\left(\hat{\beta}_j^{(non-std)}\right) = se\left(\hat{\beta}_j^{(std)}\right)/sd(g_j)$. 

In `sim_dat1`, every effect estimate has the same standard error because the standard error of $\hat{\beta}_j^{(std)}$ is approximated as $1/\sqrt{N}$ and we used a common sample size across all traits. Non-standardized effect estimates will have different standard errors for different variants because these also depend on variant allele frequencies. 


Generating non-standardized effects requires allele frequencies provided using the `af` argument which can accept a scalar, in which case the same allele frequency is used for every SNP, a vector of length `J`, or a function that takes a single argument and returns a vector of allele frequencies with length determined by the argument. If the `af` argument is provided, `sim_mv` will return all results on the non-standardized scale. 
The return object will also include a data frame, `snp_info` giving the allele frequency of each variant.


```{r}
sim_dat3 <- sim_mv(G = G,
                  N = 60000, J = 50000, 
                  h2 = c(0.3, 0.3, 0.5, 0.4), 
                  pi = 1000/50000, 
                  af = function(n){rbeta(n, 1, 5)})

head(sim_dat3$se_beta_hat)
head(sim_dat3$snp_info)
```

## Simulating Data with LD

`sim_mv` can be used to generate data with LD by inputting a list of LD matrices and corresponding allele frequency information. The function will work fastest if the LD matrix is broken into small blocks. The input data format for the LD pattern is a list of either a) matrices, b) sparse matrices (class `dsCMatrix`) or c) eigen decompositions (class `eigen`). `R_LD` is interpreted as providing blocks in a block-diagonal SNP correlation matrix.
The package contains a built in data set containing the LD pattern from Chromosome 19 in HapMap3 broken into 39 blocks. This LD pattern was estimated from the HapMap3 European subset using LDShrink. This data set can also be downloaded [here](https://zenodo.org/record/6761943#.Yrno2njMIUE). The LD pattern must be accompanied by a vector of allele frequencies with length equal to the total size of the LD pattern (i.e. the sum of the size of each block in the list).

Let's look at the built-in LD data

```{r}
data("ld_mat_list")
data("AF")

length(ld_mat_list)

sapply(ld_mat_list, class)
```




```{r}
# This prints the number of SNPs in each block
sapply(ld_mat_list, nrow)

sapply(ld_mat_list, nrow) %>% sum()

length(AF)
```

The LD pattern covers 19,490 SNPs, equal to the length of the `AF` vector. A supplied LD pattern does not have to 
be the same size as the number of SNPs we wish to generate. It will be repeated or subset as necessary to create
an LD pattern of the appropriate size.
 The built-in LD pattern corresponds to a density of about 1.2 million variants per genome. However, for this example, we will generate data for only 100k variants. This means that causal effects will be denser than they might be in more realistic data with the same number of effect variants.

```{r}
set.seed(10)
sim_dat1_LD <- sim_mv(G = G,
                      J = 1e5, 
                      N = 60000, 
                      h2 = c(0.3, 0.3, 0.5, 0.4), 
                      pi = 1000/1e5, R_LD = ld_mat_list, 
                      af = AF)

```

In data with LD, the `_joint` objects and `_marg` objects are not identical. For example, we can compare `beta_joint` and `beta_marg` for the third trait ($Z$). 

```{r}
with(sim_dat1_LD, plot(beta_joint[,3], beta_marg[,3]))
abline(0, 1, lty = 2, lwd =2, col = "red")
```

Variants with non-zero values of `beta_joint[,3]` have causal effects on $Z$ while those with non-zero values of `beta_marg[,3]` have non-zero expected marginal association with $Z$, meaning that they are in LD with at least one causal variant. In the plot, we see that many variants with no causal effect nevertheless have non-zero marginal association, as expected. The causal variants don't fall exactly on the red line because, multiple causal variants may fall into the same LD block.

### LD-Pruning, LD-Proxies, and LD Matrix Extraction

Many post-GWAS applications such as Mendelian randomization and polygenic risk score construction require an LD-pruned set of variants. `simGWAS` contains a few LD-related functions to help with pruning and testing methods that require input LD matrices. Note that all of these methods use the true LD pattern rather than estimated LD. 

The `sim_ld_prune` function will perform LD-clumping on simulated data, prioritizing variants according to a supplied `pvalue` vector. Although this argument is called `pvalue`, it can be any numeric vector used to prioritize variants. The `pvalue` argument can also accept an integer. If `pvalue = i`,  variants will be prioritized according to the p-value for the trait in the column `i`. If `pvalue` is omitted, variants will be prioritized randomly (so a different result will be obtained each re-run unless a seed  is set). 

To speed up performance, if you only need variants with $p$-value less than a certain threshold, supply the `pvalue_thresh` argument. Below we prune based on the p-values for trait $Z$ in two equivalent ways.

```{r}
pruned_set1 <- sim_ld_prune(dat = sim_dat1_LD, 
                            pvalue = 3, 
                            R_LD = ld_mat_list, 
                            r2_thresh = 0.1,
                            pval_thresh = 1e-6)
length(pruned_set1)
pval3 <- with(sim_dat1_LD, 2*pnorm(-abs(beta_hat[,3]/se_beta_hat[,3])))
pruned_set2 <- sim_ld_prune(dat = sim_dat1_LD, 
                            pvalue = pval3, 
                            R_LD = ld_mat_list, 
                            r2_thresh = 0.1,
                            pval_thresh = 1e-6)
all.equal(pruned_set1, pruned_set2)
```
`sim_ld_prune` returns a vector of indices corresponding to an LD-pruned set of variants. 

The `sim_ld_proxy` function will return indices of LD-proxies (variants with LD above a given threshold) with a supplied set of variants. Here we extract proxies for a few arbitrary variants. The `return_mat` option will cause the function to return the LD matrix for the proxies as well as the indices of proxies

```{r}
ld_proxies <- sim_ld_proxy(sim_dat1_LD, index = c(100, 400, 600), R_LD = ld_mat_list, r2_thresh = 0.64, return_mat = TRUE)
ld_proxies
```

Finally, the `sim_extract_ld` function will extract the LD matrix for a set of variants. We can use this to verify the behavior of `sim_ld_proxies` and `sim_ld_prune`. First, both of the proxies for index 600 should have correlation greater than 0.8 with index 600. The matrix returned below matches the matrix returned by `sim_ld_proxies` and shows that this is true.

```{r}
ld_mat1 <- sim_extract_ld(sim_dat1_LD, index = c(600, ld_proxies[[3]]$proxy_index), R_LD = ld_mat_list)
ld_mat1
all(abs(ld_mat1[,1]) > 0.8)
```

Next we can check that the variants in the LD-pruned set have no mutual correlations greater than $\sqrt(0.1) \approx 0.316$

```{r}
ld_mat2 <- sim_extract_ld(sim_dat1_LD, index = pruned_set1, R_LD = ld_mat_list)
diag(ld_mat2) <- 0 # remove the diagonal
all(ld_mat2^2 < 0.1)
```

## Specifying Sample Size, Sample Overlap, and Environmental Correlation

If two GWAS are performed on different traits using overlapping samples, the sampling errors of effect estimates will be correlated.
If the two GWAS have sample sizes $N_1$ and $N_2$ with $N_c$ overlapping samples, then the correlation of 
$\hat{z}_{1j}$ and $\hat{z}_{2j}$, $z$-scores for variant $j$ in study 1 and study 2, is approximately $\frac{N_c}{\sqrt{N_1 N_2}} \rho_{1,2}$ where $\rho_{1,2}$ is the observational trait correlation (assuming the studies are conducted in the same super population). Below we describe how to specify the observational correlation and how to specify sample overlap.

### Specifying Sample Size and Sample Overlap


The sample size argument, `N`, can be specified as a matrix or a data frame rather than a scalar or a vector. If `N` is a matrix, it should have dimension $M\times M$ with `N[i,i]` giving the sample size of study $i$ and `N[i,j]` giving the number of overlapping samples between studies $i$ and $j$.
In data frame format, $N$ should have columns named `trait_1`, ... `trait_[M]` and `N`. The `trait_[x]` columns will be interpreted as logicals and `N` gives the number of
samples  in each combination of studies. For example, the following specifications for two traits are equivalent.

```{r}
N <- matrix(c(60000, 30000, 30000, 60000), nrow = 2, ncol = 2)
N

Ndf <- data.frame(trait_1 = c(1, 1, 0), 
                  trait_2 = c(0, 1, 1), 
                  N = rep(30000, 3))
Ndf
```

The data frame format contains more information than the matrix format (for more than two traits) and is
required to simulate individual level data using `sim_gwas_from_b` which (covered in a different vignette).
To simulate summary statistics, either format can be used. 

### Understanding Genetic and Environmental Covariance

In the model used by `simGWAS`, each trait has a direct genetic component, a direct environmental component, and components from effects of other traits in the DAG. For example, in the four trait DAG we have been working with, the underlying model really looks like this:

```{r, echo=FALSE, fig.align='center', fig.width = 5}

n <- create_node_df(n = 12, label = c("X", "Y", "Z", "W", 
                                      "Gx", "Ex", "Gz", "Ez", 
                                      "Gy", "Ey", "Gw", "Ew"), 
                    fontname = "Helvetica", 
                    fontsize = 10, 
                    width = 0.3, 
                    fillcolor = "white", 
                    fontcolor = "black",
                    color = c(rep("black", 4), rep("blue", 8)), 
                    x = c(0, 1, 1, 2, -0.5, -0.5, 
                          0.8, 1.2, 0.8, 1.2, 
                          2.5, 2.5), 
                    y = c(0, -0.5, 1, 0, 0.25, -0.25, 
                          1.5, 1.5, -1, -1, 
                          0.25, -0.25))
e <- create_edge_df(from = c(d$from, 5, 6, 7, 8, 9, 10, 11, 12), to = c(d$to, 1, 1, 3, 3, 2, 2, 4, 4), minlen = 1,  color = "black", 
                    label = round(d$value, digits = 3))
g <- create_graph(nodes_df = n, edges_df = e)

render_graph(g)
```


In this picture, $G_x$, $G_y$, $G_z$, and $G_w$ are direct genetic components of each trait and $E_x$, $E_y$, $E_z$, and $E_w$ are direct environmental components. We always assume that the direct genetic components are independent of each other and of the environmental components. By default, we also assume that the environmental components are independent of each other (so all blue circles in the picture above are mutually independent). This means that, by default, the observational trait correlation is explained completely by the specified DAG. In this case, the default trait correlation is 

```{r}
sim_dat1$trait_corr
```

The simulation data object contains four matrices that describe trait covarince, `Sigma_E`, the total environmental trait covariance, `Sigma_G` the total genetic trait covariance, `trait_corr`, the trait correlation equal to `Sigma_G + Sigma_E`, and `R`, the row correlation of `beta_hat`. `R` is equal to `trait_corr` scaled by the a matrix of sample overlap proportions. 


`Sigma_G` is always determined by the DAG and the heritabilities.
Currently, there are two ways to modify `Sigma_E`. The first is to specify `R_obs` which directly specifies the observational trait correlation (`trait_corr` in the returned obeject). In some cases, it is possible to request an observational correlation matrix that is impossible. For example, in our example, $Z$ has a strong negative effect on $W$ so it is not possible that all four traits are mutually strongly positively correlated. We can get an error using

```{r, error = TRUE}
R_obs <- matrix(0.8, nrow = 4, ncol = 4)
diag(R_obs) <- 1

wont_run <- sim_mv(G = G,
                   J = 50000,
                  N = 60000,  
                  h2 = c(0.3, 0.3, 0.5, 0.4), 
                  pi = 1000/50000, 
                  R_obs = R_obs )
```

A quick way to find out if your desired observational correlation is feasible is to compute `R_obs - Sigma_G` and check that this matrix is positive definite (i.e. check that it has all positive eigenvalues). 

An alternative way to specify the environmental correlation is to specify `R_E` which gives the total correlation of environmental components. Importantly, `R_E` is the correlation of the **total** environmental components, not the direct environmental components shown in the graph above. `R_E` will be equal to `cov2cor(Sigma_E)`. Any positive definite correlation matrix is a valid input for `R_E`, so we could use

```{r}
R_E <- matrix(0.8, nrow = 4, ncol = 4)
diag(R_E) <- 1

sim_dat4 <- sim_mv(G = G,
                   J = 50000,
                  N = 60000,  
                  h2 = c(0.3, 0.3, 0.5, 0.4), 
                  pi = 1000/50000, 
                  R_E = R_E)
```

which results in a total trait correlation of 

```{r}
sim_dat4$trait_corr
```

It is not currently possible to specify the correlation of the direct environmental components. 

Importantly, the environmental covariance and observational trait correlation only influence the distribution of summary statistics if there is overlap between GWAS samples. This means that `sim_dat3` in the previous code block is actually a sample from exactly the same distribution as `sim_dat1`, because our specification has no sample overlap. We can tell that this is the case because `sim_dat4$R` is the identity, indicating that all summary statistics are independent across traits.

```{r}
sim_dat4$R
```


Below we combine the sample size specification options and the trait correlation specification options to produce data that are affected by the trait correlation. 
We will keep using the same 4 trait DAG. We specify that all four GWAS have sample size 60,000 and 
there are 30,000 samples overlapping between any pair of GWAS.
`simGWAS` assumes that there is no sub-population structure, so the trait correlation is the same in any subset of samples. This means that it doesn't matter if the same 30,000 samples are in all studies or if different sets overlap between different pairs of studies.
We also specify an environmental correlation matrix in which the pairwise correlation in environmental effects for any pair of traits is 0.4. 

```{r}
R_E <- matrix(0.4, nrow = 4, ncol = 4)
diag(R_E) <- 1
N <- matrix(30000, nrow = 4, ncol = 4)
diag(N) <- 60000
N
```

```{r}
set.seed(10)
sim_dat4 <- sim_mv(G = G,
                  N = N, J = 1e5, R_E = R_E,
                  h2 = c(0.3, 0.3, 0.5, 0.4), 
                  pi = 1000/1e5)
```

We can now see that `sim_dat4$R` is not the identity:
```{r}
sim_dat3$trait_corr
sim_dat3$R
```

Note that we did not have to specify `R_E` to get a non-identity value for `R`. If we use the default value (`NULL`), the data will have the observational correlation created by the DAG structure, and this will be reflected in `R` if there is sample overlap. 

## Generating Data for Multiple GWAS of the Same Trait 

In some cases, you may want to generate multiple sets of summary statistics for the same set of effect sizes. This
would mimic performing multiple GWAS on the same trait. The function `gen_bhat_from_b` allows you to do this. This function takes as input
a matrix of either standardized or non-standardized joint (causal) effects to `b_joint_std` or `b_joint`. The function also requires the trait correlation matrix
and the sample size argument. Optionally, `af` and `R_LD` can be supplied. The `est_s` argument functions in the same way as in `sim_mv`. 

Below, we generate new GWAS data for the effects in `sim_dat1_LD`. Here we use the same LD pattern used originally but we could have done otherwise. For example, we could simulate GWAS in samples with different ancestry but supplying a different LD pattern.

```{r}
sim_dat2_LD <- gen_bhat_from_b(b_joint = sim_dat1_LD$beta_joint, 
                               trait_corr = sim_dat1_LD$trait_corr, 
                               N = 40000, 
                               R_LD = ld_mat_list, af = AF)
```
The resulting simulation data object only contains effect estimates, standard errors, `R`, and `snp_info`. All other information should match the original data set. 

Below we compare effect estimates in the new study and the old study for trait $X$.
```{r}
plot(sim_dat2_LD$beta_hat[,1], sim_dat1_LD$beta_hat[,1])
abline(0, 1, col = "red", lty = 2, lwd = 2)
```

Our first simulation object `sim_dat1` was generated with no LD and without supplying the `af` argument, so the `beta_joint` values for that object represent standardized effects. If we were generating secondary studies from this object, we should use the `b_joint_std` argument rather than `b_joint` in the call to `gen_bhat_from_b`. If you are not sure if you have standardized or non-standardized effects, check the `snp_info` table. If the `AF` column is equal to `NA` then the object contains standardized effects. Otherwise, it contains non-standardized effects.
